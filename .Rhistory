labels[i, ] <- unlist(plotted_est$labels)
# now add asterisks if the confidence intervals do NOT pass through zero
ci_bounds <- array(unlist(plotted_est$cis), dim = c(2, 11))
for (j in 1:11) {
if (ci_bounds[1, j] > 0 & ci_bounds[2, j] > 0) {
point_estimates[i, j] <- paste(point_estimates[i, j], "*", sep = "")
dummy_matrix[i, j] <- 1
}
}
}
est_eff <- estimateEffect(c(18) ~ organization + date, selected_32_org, metadata = ant_stm$meta, uncertainty = "Global")
plotted_est <- plot(est_eff, "organization", model = selected_32_org, main = graph_title, ci.level = 0.9)
plotted_est$cis
plotted_est$means
# Now remove the rows (topics) that we didn't want
point_estimates <- na.omit(point_estimates)
# Label the rows and the columns
point_est_df <- data.frame(point_estimates, row.names = topic_names)
# just check that all of the covars are in the same order for each topic
View(labels)
topic_labels <- c("AARI", "ACECRC", "ARC", "ASOC", "ATS", "CCAMLR", "CCAS", "COMNAP", "IAATO", "IMAS", "SCAR")
colnames(point_est_df) <- topic_labels
write.csv(point_est_df, file = "point_estimates2.csv")
write.csv(point_est_df, file = "point_estimates2.csv")
dummy_df <- dummy_matrix[topics_for_corr]
dummy_df
dummy_df <- dummy_matrix[topics_for_corr, ]
View(dummy_df)
View(dummy_matrix)
View(dummy_matrix)
dumy_df
dummy_df
dummy_matrix <- data.frame(dummy_matrix, row.names = topic_names)
colnames(dummy_matrix) <- topic_labels
write.csv(dummy_matrix, file = "dichotomized_version.csv")
dummy_df <- data.frame(dummy_df, row.names = topic_names)
colnames(dummy_df) <- topic_labels
write.csv(dummy_df, file = "dichotomized_version.csv")
libraries <- c("foreign", "utils", "dplyr", "devtools", "quanteda", "ggplot2", "topicmodels", "stm", "lda", "LDAvis", "jsonlite", "stringi", "stmBrowser")
lapply(libraries, require, character.only=TRUE)
warnings()
install.packages("foreign")
install.packages("foreign")
install.packages("quanteda")
install.packages("dplyr")
install.packages("ggplot2")
install.packages(c("stm", "lda"))
install.packages(c("devtools, "jsonlite", "rjson", "LDAvis", topicmodels"))
install.packages(c("devtools", "jsonlite", "rjson", "LDAvis", topicmodels"))
)
quit
)
""
install.packages(c("devtools", "jsonlite", "rjson", "LDAvis", topicmodels"))
install.packages(c("devtools", "jsonlite", "rjson", "LDAvis", "topicmodels"))
""
install.packages(c("devtools", "jsonlite", "rjson", "LDAvis", "topicmodels"))
install.packages(c("stargazer", "stringr", "LIWCalike", "forecast", "lmtest", "strucchange", "vars", "tseries", "urca", "mlogit", "reshape2", "MCDM", "car", "nnet", "stringi", "depmixS4"))
load("~/Dropbox/Shared_with_Leslie/simulations_LH.RData")
load("~/un-analysis/un_img_new_dfm.RData")
FindTopicsNumber_plot(result)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "jsonlite", "stringi")
lapply(libraries, require, character.only=TRUE)
FindTopicsNumber_plot(result)
FindTopicsNumber_plot(result1)
FindTopicsNumber_plot(result2
)
FindTopicsNumber_plot(result3)
model
Topic <- topics(model[["VEM"]], 1)
topics(model)
topics(model, 1)
Terms <- terms(model, 10)
Terms
model_50 <- model
load("/Users/lesliehuang/Dropbox/Antarctica topic models/STM_K32.RData")
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/lesliehuang/Dropbox/Antarctica topic models/")
load("STM_K32.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "devtools", "quanteda", "ggplot2", "topicmodels", "stm", "lda", "LDAvis", "jsonlite", "stringi", "stmBrowser")
lapply(libraries, require, character.only=TRUE)
topics_for_corr = c(1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 14, 15, 18, 20, 21, 25, 30, 31, 32)
topic_names <- c("Penguins", "Conservation of fish, birds, marine mammals", "CCAMLR reporting", "Geological surveying", "ATS Scientific Committee", "Climate in S. Ocean", "Protected areas", "Krill", "Whale stocks", "Tourism", "Environment protocol", "Data collection", "Marine search and rescure", "Marine mammals", "Station environmental impact", "Marine protected areas", "Boat tourism", "Temperature monitoring", "ATCM rulemaking")
dt <- make.dt(selected_32_org)
View(dt)
antarctica_corpus$docvars
docvars(antarctica_corpus)
dfm_docvars
View(dfm_docvars)
View(dt)
View(dfm_docvars)
rownames(dt)
rownames(dt) <- dfm_docvars$organization
names_with_rows <- paste(dfm_docvars$organization, rownames(dt))
rownames(dt) <- names_with_rows
View(dt)
dt$docnum <- names_with_rows
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, org_name %in% docnum)
tab_name <- paste(org_name, " proportions", sep = "")
assign(tab_name, x)
}
View(`AARI proportions`)
View(`ARC proportions`)
"a" in "abc"
"a" %in% "abc"
"a" %in% "a"
dt <- make.dt(selected_32_org)
names_with_rows <- paste(dfm_docvars$organization, rownames(dt))
rownames(dt) <- names_with_rows
dt$doc_org <- dfm_docvars$organization
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, org_name %in% docnum)
tab_name <- paste(org_name, " proportions", sep = "")
assign(tab_name, x)
}
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, org_name %in% doc_org)
tab_name <- paste(org_name, " proportions", sep = "")
assign(tab_name, x)
}
View(`ACECRC proportions`)
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, doc_org == org_name)
tab_name <- paste(org_name, " proportions", sep = "")
assign(tab_name, x)
}
View(`SCAR proportions`)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/lesliehuang/Dropbox/Antarctica topic models/")
load("STM_K32.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "devtools", "quanteda", "ggplot2", "topicmodels", "stm", "lda", "LDAvis", "jsonlite", "stringi", "stmBrowser")
lapply(libraries, require, character.only=TRUE)
topics_for_corr = c(1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 14, 15, 18, 20, 21, 25, 30, 31, 32)
topic_names <- c("Penguins", "Conservation of fish, birds, marine mammals", "CCAMLR reporting", "Geological surveying", "ATS Scientific Committee", "Climate in S. Ocean", "Protected areas", "Krill", "Whale stocks", "Tourism", "Environment protocol", "Data collection", "Marine search and rescure", "Marine mammals", "Station environmental impact", "Marine protected areas", "Boat tourism", "Temperature monitoring", "ATCM rulemaking")
dt <- make.dt(selected_32_org)
names_with_rows <- paste(dfm_docvars$organization, rownames(dt))
rownames(dt) <- names_with_rows
dt$doc_org <- dfm_docvars$organization
# Create separate tables of documents x topics for each organization
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, doc_org == org_name)
tab_name <- paste(org_name, "_proportions", sep = "")
assign(tab_name, x)
}
AARI_proportions.colSums()
colSums(AARI_proportions)
tab_names <- c()
tab_names
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, doc_org == org_name)
tab_name <- paste(org_name, "_proportions", sep = "")
tab_names <- c(tab_names, tab_name)
assign(tab_name, x)
}
proportions_by_org <- matrix(data = NA, nrow = 11, ncol = 32)
View(AARI_proportions)
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, doc_org == org_name)
x <- x[, 2:33]
tab_name <- paste(org_name, "_proportions", sep = "")
tab_names <- c(tab_names, tab_name)
assign(tab_name, x)
}
View(AARI_proportions)
for (i in 1:length(tab_names)) {
current_tab <- get(tab_names[i])
proportions_by_org[i, ] <- colSums(current_tab)
}
length(tab_names)
tab_names
tab_names <- c()
# Create separate tables of documents x topics for each organization
for (org_name in unique(dfm_docvars$organization) ) {
x <- filter(dt, doc_org == org_name)
x <- x[, 2:33]
tab_name <- paste(org_name, "_proportions", sep = "")
tab_names <- c(tab_names, tab_name)
assign(tab_name, x)
}
# Create table of organization totals
proportions_by_org <- matrix(data = NA, nrow = 11, ncol = 32)
for (i in 1:length(tab_names)) {
current_tab <- get(tab_names[i])
proportions_by_org[i, ] <- colSums(current_tab)
}
View(`AARI proportions`)
proportions_by_org
proportions_by_org <- as.data.frame(proportions_by_org, row.names = tab_names)
View(proportions_by_org)
colnames(proportions_by_org) <- colnames(AARI_proportions)
View(proportions_by_org)
View(`AARI proportions`)
View(proportions_by_org)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/lesliehuang/Dropbox/Antarctica topic models/Memos")
load("../STM_K32.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "devtools", "quanteda", "ggplot2", "topicmodels", "stm", "lda", "LDAvis", "jsonlite", "stringi", "stmBrowser")
lapply(libraries, require, character.only=TRUE)
topics_for_corr = c(1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 14, 15, 18, 20, 21, 25, 30, 31, 32)
topic_names <- c("Penguins", "Conservation of fish, birds, marine mammals", "CCAMLR reporting", "Geological surveying", "ATS Scientific Committee", "Climate in S. Ocean", "Protected areas", "Krill", "Whale stocks", "Tourism", "Environment protocol", "Data collection", "Marine search and rescure", "Marine mammals", "Station environmental impact", "Marine protected areas", "Boat tourism", "Temperature monitoring", "ATCM rulemaking")
proportions_by_org <- matrix(data = NA, nrow = 11, ncol = 32)
for (i in 1:length(tab_names)) {
current_tab <- get(tab_names[i])
proportions_by_org[i, ] <- colMeans(current_tab)
}
View(proportions_by_org)
rowSums(proportions_by_org)
# Convert to dataframe
proportions_by_org <- as.data.frame(proportions_by_org, row.names = tab_names)
colnames(proportions_by_org) <- colnames(AARI_proportions)
View(proportions_by_org)
rowSums(proportions_by_org)
proportions_by_org_grouped <- transmute(proportions_by_org,
Species = Topic1 + Topic2 + Topic0 + Topic10 + Topic20,
SciResearch = Topic4 + Topic15 + Topic31 + Topic7, EnvirProtect = Topic8 + Topic21 + Topic25,
Tourism = Topic11 + Topic30  + Topic18,
InterGovCooperation = Topic32 + Topic3 + Topic6 + Topic14,
Junk = Topic5 + Topic12 + Topic13 + Topic16 + Topic17 + Topic19 + Topic22 + Topic23 + Topic24 + Topic26 + Topic27 + Topic28 + Topic29)
proportions_by_org_grouped <- transmute(proportions_by_org,
Species = Topic1 + Topic2 + Topic9 + Topic10 + Topic20,
SciResearch = Topic4 + Topic15 + Topic31 + Topic7, EnvirProtect = Topic8 + Topic21 + Topic25,
Tourism = Topic11 + Topic30  + Topic18,
InterGovCooperation = Topic32 + Topic3 + Topic6 + Topic14,
Junk = Topic5 + Topic12 + Topic13 + Topic16 + Topic17 + Topic19 + Topic22 + Topic23 + Topic24 + Topic26 + Topic27 + Topic28 + Topic29)
proportions_by_org_grouped
View(proportions_by_org_grouped)
rowSums(proportions_by_org_grouped)
rownames(proportions_by_org_grouped) <- rownames(proportions_by_org)
View(proportions_by_org_grouped)
write.csv(proportions_by_org, "topic_proportions_by_org.csv")
write.csv(proportions_by_org, file = "topic_proportions_by_org.csv")
View(proportions_by_org)
getwd()
setwd("./")
getwd()
dirname(parent.frame(2)$ofile)
source("un-analysis.cluster.R")
dirname("un-analysis-cluster.R")
source("un-analysis-cluster.R")
Sys.getenv()
Sys.getenv("home")
Sys.getenv("R_HOME")
Sys.getenv("HOME")
parallel::detect.Cores()
detect.Cores()
detectCores()
parallel::detectCores()
load("/Users/lesliehuang/un-analysis/un_img_new_dfm.RData")
rm(result)
rm(result3)
rm(result2)
save.image("un_base_workspace.RData")
num_cores <- max(parallel::detectCores() - 1, 1)
print(num_cores)
print(num_cores)
load("/Users/lesliehuang/Desktop/un_img_new_dfm_10-30-17.RData")
load("/Users/lesliehuang/Desktop/un_img_new_dfm_75.RData")
load("~/Desktop/un_model_50.RData")
load("~/Desktop/un_model_65.RData")
load("~/Desktop/un_model_75.RData")
save.image("~Desktop/un_models.RData")
save.image("~/Desktop/un_models.RData")
View(result_20)
load("/Users/lesliehuang/un_findk_21.RData")
load("/Users/lesliehuang/un_findk_22.RData")
load("/Users/lesliehuang/un_findk_25.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/un_findk_30.RData")
load("/Users/lesliehuang/Desktop/un_tuning_combined.RData")
load("/Users/lesliehuang/un_findk_29.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/un_tuning_combined.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/un_findk_32.RData")
load("/Users/lesliehuang/un_findk_37.RData")
load("/Users/lesliehuang/un_findk_40.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/un_findk_50.RData")
load("/Users/lesliehuang/un_findk_51.RData")
load("/Users/lesliehuang/un_findk_53.RData")
load("/Users/lesliehuang/un_findk_58.RData")
load("/Users/lesliehuang/un_tuning_combined.RData")
save.image("un_tuning_combined.RData")
View(result_20)
load("/Users/lesliehuang/Desktop/un_findk1.RData")
View(result)
View(result_40)
View(result)
View(result_40)
View(result)
View(result_50)
View(result)
load("/Users/lesliehuang/un_findk_55.RData")
load("/Users/lesliehuang/un_findk_57.RData")
load("/Users/lesliehuang/un_findk_60.RData")
load("/Users/lesliehuang/un_findk_61.RData")
load("/Users/lesliehuang/un_findk_63.RData")
load("/Users/lesliehuang/un_findk_65.RData")
load("/Users/lesliehuang/un_findk_68.RData")
load("/Users/lesliehuang/un_findk_75.RData")
load("/Users/lesliehuang/un_tuning_combined.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/un_findk_95.RData")
load("/Users/lesliehuang/un_findk_93.RData")
load("/Users/lesliehuang/un_findk_90.RData")
load("/Users/lesliehuang/un_findk_89.RData")
load("/Users/lesliehuang/un_findk_87.RData")
load("/Users/lesliehuang/un_findk_82.RData")
load("/Users/lesliehuang/un_findk_81.RData")
load("/Users/lesliehuang/un_findk_79.RData")
load("/Users/lesliehuang/un_findk_77.RData")
load("/Users/lesliehuang/un_findk_72.RData")
load("/Users/lesliehuang/un_findk_69.RData")
load("/Users/lesliehuang/un_findk_68.RData")
load("/Users/lesliehuang/un_findk_64.RData")
load("/Users/lesliehuang/un_findk_47.RData")
load("/Users/lesliehuang/un_findk_42.RData")
load("/Users/lesliehuang/un_findk_80.RData")
load("/Users/lesliehuang/un_findk_85.RData")
load("/Users/lesliehuang/un_tuning_combined.RData")
save.image("un_tuning_combined.RData")
load("/Users/lesliehuang/perplexity_65.RData")
perplexity_test_60
load("/Users/lesliehuang/perplexitytest_60.RData")
load("/Users/lesliehuang/perplexitytest_65.RData")
load("/Users/lesliehuang/perplexitytest_70.RData")
load("/Users/lesliehuang/perplexitytest_75.RData")
load("/Users/lesliehuang/perplexitytest_80.RData")
save.image("perplexitytest_combined.RData")
View(perplexity_results_55)
View(perplexity_results_55)
load("/Users/lesliehuang/kfold_perplexity_60.RData")
load("/Users/lesliehuang/kfold_perplexity_65.RData")
View(perplexity_results_60)
load("/Users/lesliehuang/kfold_perplexity_70.RData")
load("/Users/lesliehuang/kfold_perplexity_75.RData")
load("/Users/lesliehuang/kfold_perplexity_80.RData")
View(perplexity_results_55)
save.image("perplexity_kfold_combined.RData")
load("/Users/lesliehuang/kfold_perplexity_40.RData")
save(tab, file = "test.RData")
View(tab)
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
title(main = "Results from LDA Tuning")
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
title(main = "Results from LDA Tuning")
plot(tuning_plot)
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
ggsave("tuning_plot.png", "png")
png("tuning_plot.png")
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
dev.off()
png("tuning_plot.png", width = 1200, height = 800)
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
dev.off()
png("tuning_plot.png", width = 1500, height = 800)
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
dev.off()
qplot(seq(40,89,1), combined_perplexity_results$mean_log, xlab = "Number of topics", ylab = "Mean of log held-out perplexity from 10-fold cross-validation") + geom_line() + ggtitle("Results from held-out perplexity from 10-fold cross-validation")
ggsave("logperplexity_results.png", device = "png")
View(combined_perplexity_results)
# Leslie Huang
# Combine all ldatuning results from cluster jobs
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("perplexity_kfold_combined.RData")
# This workspace combined results of 10 fold cross validated held out perplexity for models that were individually run on the HPC cluster. See the batch_kfold_perplexity dir for details
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "ggplot2", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda")
lapply(libraries, require, character.only=TRUE)
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, ncol = 10, nrow = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[i, ] <- get(perplexity_result_dfs[i])
}
rownames(combined_perplexity_results) <- perplexity_result_dfs
combined_perplexity_results$mean_log <- rowMeans(log(combined_perplexity_results))
save.image("perplexity_kfold_combined.RData")
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
# Bring all the results together
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
# Examine models with different k
# Sparsity for DFM: min = 0.5%, max = 90%
# TM settings: 5 starts, 4000 iter, 1000 burnin, 500 thin
# Plot the results from LDAtuning
png("tuning_plot.png", width = 1500, height = 800)
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
dev.off()
# Plot the results from 10-fold heldout perplexity
qplot(seq(40,89,1), combined_perplexity_results$mean_log, xlab = "Number of topics", ylab = "Mean of log held-out perplexity from 10-fold cross-validation") + geom_line() + ggtitle("Results from held-out perplexity from 10-fold cross-validation")
ggsave("logperplexity_results.png", device = "png")
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
terms_m50 <- generate_wordlist(model_50, 20)
#write.csv(terms_m50, file = "terms_m50.csv")
terms_m65 <- generate_wordlist(model_65, 20)
#write.csv(terms_m65, file = "terms_m65.csv")
terms_m75 <- generate_wordlist(model_75, 20)
#write.csv(terms_m75, file = "terms_m75.csv")
terms_m80 <- generate_wordlist(model_80, 20)
#write.csv(terms_m80, file = "terms_m80.csv")
save.image("full_tm_workspace.RData")
load("/Users/lesliehuang/kfold_perplexity_90.RData")
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "ggplot2", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda")
lapply(libraries, require, character.only=TRUE)
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, ncol = 10, nrow = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[i, ] <- get(perplexity_result_dfs[i])
}
rownames(combined_perplexity_results) <- perplexity_result_dfs
combined_perplexity_results$mean_log <- rowMeans(log(combined_perplexity_results))
save.image("perplexity_kfold_combined.RData")
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
qplot(seq(40,90,1), combined_perplexity_results$mean_log, xlab = "Number of topics", ylab = "Mean of log held-out perplexity from 10-fold cross-validation") + geom_line() + ggtitle("Results from held-out perplexity from 10-fold cross-validation")
ggsave("logperplexity_results.png", device = "png")
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
terms_m50 <- generate_wordlist(model_50, 20)
#write.csv(terms_m50, file = "terms_m50.csv")
terms_m65 <- generate_wordlist(model_65, 20)
#write.csv(terms_m65, file = "terms_m65.csv")
terms_m75 <- generate_wordlist(model_75, 20)
#write.csv(terms_m75, file = "terms_m75.csv")
terms_m80 <- generate_wordlist(model_80, 20)
#write.csv(terms_m80, file = "terms_m80.csv")
save.image("full_tm_workspace.RData")
load("un-analysis/full_tm_workspace.RData")
load("/Users/lesliehuang/un-analysis/full_tm_workspace.RData")
mean_topic_distr
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
install.packages("LDAvis")
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
png("tuning_plot.png", width = 1500, height = 800)
tuning_plot <- FindTopicsNumber_plot(ldatuning_results[, c(1, 3:5)]) # exclude Griffiths because it's NA
dev.off()
tuning_plot
qplot(seq(40,90,1), combined_perplexity_results$mean_log, xlab = "Number of topics", ylab = "Mean of log held-out perplexity from 10-fold cross-validation") + geom_line() + ggtitle("Results from held-out perplexity from 10-fold cross-validation")
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
terms_m50 <- generate_wordlist(model_50, 20)
#write.csv(terms_m50, file = "terms_m50.csv")
terms_m65 <- generate_wordlist(model_65, 20)
#write.csv(terms_m65, file = "terms_m65.csv")
terms_m75 <- generate_wordlist(model_75, 20)
#write.csv(terms_m75, file = "terms_m75.csv")
terms_m80 <- generate_wordlist(model_80, 20)
#write.csv(terms_m80, file = "terms_m80.csv")
# Get topic proportions over documents for K = 75
topic_distr_over_docs <- model_75@gamma
mean_topic_distr <- colMeans(topic_distr_over_docs)
qplot(seq(1,75,1), mean_topic_distr, xlab = "Topic number", ylab = "Mean proportion of documents (0.01 = 1%)") + geom_point() + ggtitle("Mean topic distribution over documents with 75 topics")
mean_topic_distr
View(mean_topic_distr)
qplot(seq(1,75,1), mean_topic_distr, xlab = "Topic number", ylab = "Mean proportion of documents (0.01 = 1%)") + geom_point() + ggtitle("Mean topic distribution over documents with 75 topics")
ggsave("topicdistr.png", device = "png")
save.image("full_tm_workspace.RData")
class(mean_topic_distr)
write.csv(list(mean_topic_distr), file="mean_topic_distr.csv")
save.image("full_tm_workspace.RData")
