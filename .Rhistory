### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda", "caret")
lapply(libraries, require, character.only=TRUE)
load("un_base_workspace.RData")
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 5,
seed = 0:4,
best = TRUE
)
# Set up 10-fold cross-validation
fold_size <- floor(ndoc(un_dfm) * .1)
num_folds <- 10
indices <- sample(ndoc(un_dfm))
split_indices <- split(indices, 1:num_folds)
for (fold in split_indices) {
fold_indices <- fold
fold_docnames <- docnames(un_dfm)[fold_indices]
fold_name <- paste("fold_", i, sep = "")
assign(fold_name, dfm_select(un_dfm, documents = fold_docnames, select = "keep"))
}
i <- 1
for (fold in split_indices) {
fold_indices <- fold
fold_docnames <- docnames(un_dfm)[fold_indices]
fold_name <- paste("fold_", i, sep = "")
assign(fold_name, dfm_select(un_dfm, documents = fold_docnames, select = "keep"))
i <- i + 1
}
for (i in 1:num_folds) {
while (i < num_folds) {
fold_name <- paste("fold_", i, sep ="")
print(dfm)
fold_dfm <- dfm_sample(dfm, size = fold_size, replace = FALSE) # randomly sample one fold from the base dfm
assign("dfm", dfm_select(dfm, documents = docnames(fold_dfm), select = "remove")) # now remove that fold from the base dfm so that it won't be included next time
assign(fold_name, fold_dfm) # reassign
rm(fold_dfm)
}
# assign the last fold outside of the loop to account for uneven fold size (ndocs / folds was a frac)
assign(paste("fold_", num_folds, sep = ""), dfm)
}
dfm <- un_dfm
for (i in 1:num_folds) {
while (i < num_folds) {
fold_name <- paste("fold_", i, sep ="")
print(dfm)
fold_dfm <- dfm_sample(dfm, size = fold_size, replace = FALSE) # randomly sample one fold from the base dfm
assign("dfm", dfm_select(dfm, documents = docnames(fold_dfm), select = "remove")) # now remove that fold from the base dfm so that it won't be included next time
assign(fold_name, fold_dfm) # reassign
rm(fold_dfm)
}
# assign the last fold outside of the loop to account for uneven fold size (ndocs / folds was a frac)
assign(paste("fold_", num_folds, sep = ""), dfm)
}
un_dfm(txts[1:2])
docvars(un_dfm)
dfm_subset(un_dfm, docs = "Bolivia (Plurinational State of)_1994_Antonio Aranibar Quiroga_ID01261")
dfm_subset(un_dfm, country = "Afghanistan")
dfm_subset(un_dfm, country == "Afghanistan")
dfm_subset(un_dfm, 1)
x<- dfm_subset(un_dfm, 1)
x
View(x)
x<- dfm_subset(un_dfm, 1:444)
View(x)
i <- 1
for (fold in split_indices) {
fold_indices <- fold
fold_name <- paste("fold_", i, sep = "")
assign(fold_name, dfm_subset(un_dfm, fold_indices))
i <- i + 1
}
class(1:10)
class(split_indices$`1`)
split_indices$`1`
x<- dfm_subset(un_dfm, c(1,4447))
View(x)
x<- dfm_subset(un_dfm, c([1,4447]))
x<- dfm_subset(un_dfm, c(1, 10))
x
View(x)
x<- dfm_subset(un_dfm, docs = c(1,10))
x<- dfm_subset(un_dfm, docs == c(1,10))
docvars(un_dfm, docname = docnames(un_dfm))
docvars(un_dfm, docname) <- docnames(un_dfm)
docvars(un_dfm, "docname") <- docnames(un_dfm)
i <- 1
for (fold in split_indices) {
fold_docnames <- docnames(un_dfm)[fold]
fold_name <- paste("fold_", i, sep = "")
assign(fold_name, dfm_subset(un_dfm, docname == fold_docnames))
i <- i + 1
}
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda", "caret")
lapply(libraries, require, character.only=TRUE)
load("un_base_workspace.RData")
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 5,
seed = 0:4,
best = TRUE
)
docvars(un_dfm, "docname") <- docnames(un_dfm)
# Set up 10-fold cross-validation
fold_size <- floor(ndoc(un_dfm) * .1)
num_folds <- 10
indices <- sample(ndoc(un_dfm))
split_indices <- split(indices, 1:num_folds)
test_names <- docnames(un_dfm)[split_indices$`1`]
test_names
x <- dfm_subset(un_dfm, docname = test_names)
x <- dfm_subset(un_dfm, docname == test_names)
x <- dfm_subset(un_dfm, test_names)
x <- dfm_subset(un_dfm[test_names])
un_dfm[1]
un_dfm[1:10]
View(un_dfm[1:10])
View(un_dfm[c(1,4447)])
split_indices[1]
split_indices[2]
split_indices[3]
un_dfm[-1]
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda", "caret")
lapply(libraries, require, character.only=TRUE)
load("un_base_workspace.RData")
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 5,
seed = 0:4,
best = TRUE
)
docvars(un_dfm, "docname") <- docnames(un_dfm)
# Set up 10-fold cross-validation
fold_size <- floor(ndoc(un_dfm) * .1)
num_folds <- 10
indices <- sample(ndoc(un_dfm))
split_indices <- split(indices, 1:num_folds)
for (i in 1:num_folds) {
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, un_dfm[split_indices[i]])
assign(training_name, un_dfm[-split_indices[i]])
}
for (i in 1:num_folds) {
indices <- split_indices[i]
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, un_dfm[indices])
assign(training_name, un_dfm[-indices])
}
class(split_indices[1])
class(unlist(split_indices[1]))
for (i in 1:num_folds) {
indices <- unlist(split_indices[i])
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, un_dfm[indices])
assign(training_name, un_dfm[-indices])
}
for (i in 1:num_folds) {
indices <- unlist(split_indices[i])
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, convert(un_dfm[indices], to = "topicmodels"))
assign(training_name, convert(un_dfm[-indices], to = "topicmodels")
}
for (i in 1:num_folds) {
indices <- unlist(split_indices[i])
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, convert(un_dfm[indices], to = "topicmodels"))
assign(training_name, convert(un_dfm[-indices], to = "topicmodels"))
}
save.image("perplexity_k10_base.RData")
library("foreach", lib.loc="~/un-analysis/packrat/lib/x86_64-apple-darwin15.6.0/3.4.1")
# Leslie Huang
# Combine all ldatuning results from cluster jobs
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda", "caret")
lapply(libraries, require, character.only=TRUE)
load("un_base_workspace.RData")
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 5,
seed = 0:4,
best = TRUE
)
docvars(un_dfm, "docname") <- docnames(un_dfm)
# Set up 10-fold cross-validation
fold_size <- floor(ndoc(un_dfm) * .1)
num_folds <- 10
indices <- sample(ndoc(un_dfm))
split_indices <- split(indices, 1:num_folds)
for (i in 1:num_folds) {
indices <- unlist(split_indices[i])
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, convert(un_dfm[indices], to = "topicmodels"))
assign(training_name, convert(un_dfm[-indices], to = "topicmodels"))
}
rm(list=ls(indices, test_name, training_name))
save.image("perplexity_k10_base.RData")
# Leslie Huang
# Combine all ldatuning results from cluster jobs
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda", "caret")
lapply(libraries, require, character.only=TRUE)
load("un_base_workspace.RData")
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 5,
seed = 0:4,
best = TRUE
)
# Set up 10-fold cross-validation
fold_size <- floor(ndoc(un_dfm) * .1)
num_folds <- 10
indices <- sample(ndoc(un_dfm))
split_indices <- split(indices, 1:num_folds)
for (i in 1:num_folds) {
indices <- unlist(split_indices[i])
test_name <- paste("test_", i, sep = "")
training_name <- paste("training_", i, sep = "")
assign(test_name, convert(un_dfm[indices], to = "topicmodels"))
assign(training_name, convert(un_dfm[-indices], to = "topicmodels"))
}
rm(list=ls(indices, test_name, training_name))
save.image("perplexity_k10_base.RData")
install.packages("doParallel")
# Leslie Huang
# Combine all ldatuning results from cluster jobs
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("perplexity_kfold_combined.RData")
# This workspace combined results of 10 fold cross validated held out perplexity for models that were individually run on the HPC cluster. See the batch_kfold_perplexity dir for details
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "stringi", "topicmodels", "ldatuning", "lda")
lapply(libraries, require, character.only=TRUE)
num_cores <- max(1, parallel::detectCores() - 1)
controls_tm <- list(
burnin = 1000,
iter = 4000,
thin = 500,
nstart = 1,
seed = 0,
best = TRUE
)
View(perplexity_results_55)
View(perplexity_results_60)
t(perplexity_results_60)
ls=list(pattern="^perplexity_results_")
ls
rm(ls)
for (result in list = ls(pattern="^perplexity_results_")) {
print(t(result))
}
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in (list = ls(pattern="^perplexity_results_")) ) {
print(t(result))
}
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in (list = ls(pattern="^perplexity_results_")) ) {
print(t(get(result)))
}
combined_perplexity_results <- data.frame()
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in (list = ls(pattern="^perplexity_results_")) ) {
combined_perplexity_results <- cbind(combined_perplexity_results, result)
}
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in (list = ls(pattern="^perplexity_results_")) ) {
combined_perplexity_results <- rbind(combined_perplexity_results, result)
}
View(combined_perplexity_results)
class(perplexity_results_55)
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(NA, row.names = perplexity_result_dfs)
class(perplexity_result_dfs)
perplexity_result_dfs
combined_perplexity_results <- data.frame(row.names = perplexity_result_dfs)
combined_perplexity_results
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in perplexity_result_dfs ) {
combined_perplexity_results <- cbind(combined_perplexity_results, result)
}
combined_perplexity_results
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(row.names = perplexity_result_dfs)
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in perplexity_result_dfs ) {
combined_perplexity_results <- cbind(combined_perplexity_results, t(get(result)))
}
data.frame(matrix(NULL, nrow = 6, ncol = 9))
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)), row.names = perplexity_result_dfs)
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)), col.names = perplexity_result_dfs)
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)))
combined_perplexity_results
colnames(combined_perplexity_results) <- perplexity_result_dfs
combined_perplexity_results
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (result in perplexity_result_dfs ) {
combined_perplexity_results <- cbind(combined_perplexity_results, t(get(result)))
}
combined_perplexity_results
View(combined_perplexity_results)
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[i,] <- cbind(combined_perplexity_results, t(get(perplexity_result_dfs[i])))
}
colnames(combined_perplexity_results) <- perplexity_result_dfs
View(combined_perplexity_results)
get(perplexity_result_dfs[1])
t(get(perplexity_result_dfs[1]))
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[, i] <- cbind(combined_perplexity_results, t(get(perplexity_result_dfs[i])))
}
colnames(combined_perplexity_results) <- perplexity_result_dfs
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)))
View(combined_perplexity_results)
colnames(combined_perplexity_results) <- perplexity_result_dfs
View(combined_perplexity_results)
combined_perplexity_results[,1]
combined_perplexity_results[1,]
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, nrow = 10, ncol = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe, columns = models, rows = folds
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[, i] <- t(get(perplexity_result_dfs[i]))
}
colnames(combined_perplexity_results) <- perplexity_result_dfs
View(combined_perplexity_results)
View(combined_perplexity_results)
View(combined_perplexity_results)
colMeans(combined_perplexity_results)
log(colMeans(combined_perplexity_results))
plot(log(colMeans(combined_perplexity_results)))
ggplot(log(colMeans(combined_perplexity_results)))
library("ggplot2")
ggplot(log(colMeans(combined_perplexity_results)))
ggplot(data = log(colMeans(combined_perplexity_results)))
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, ncol = 10, nrow = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[, i] <- get(perplexity_result_dfs[i])
}
rownames(combined_perplexity_results) <- perplexity_result_dfs
log(colMeans(combined_perplexity_results))
View(combined_perplexity_results)
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, ncol = 10, nrow = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[i, ] <- get(perplexity_result_dfs[i])
}
rownames(combined_perplexity_results) <- perplexity_result_dfs
log(colMeans(combined_perplexity_results))
View(combined_perplexity_results)
log(colMeans(combined_perplexity_results))
log(rowMeans(combined_perplexity_results))
rowMeans(log(combined_perplexity_results))
mean_perplexity <- rowMeans(log(combined_perplexity_results))
View(combined_perplexity_results)
ggplot(combined_perplexity_results, aes(x = x, y = X1))
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(log(combined_perplexity_results))))
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(log(combined_perplexity_results)))) + geom_plot()
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(log(combined_perplexity_results)))) + geom_dotplot()
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(combined_perplexity_results)) ) + geom_dotplot()
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(combined_perplexity_results)) ) + geom_dotplot()
perplexity_result_dfs <- (list = ls(pattern="^perplexity_results_"))
combined_perplexity_results <- data.frame(matrix(NA, ncol = 10, nrow = length(perplexity_result_dfs)))
# Combine perplexity results into new dataframe
for (i in 1:length(perplexity_result_dfs) ) {
combined_perplexity_results[i, ] <- get(perplexity_result_dfs[i])
}
rownames(combined_perplexity_results) <- perplexity_result_dfs
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = rowMeans(combined_perplexity_results)) ) + geom_dotplot()
combined_perplexity_results$mean_log <- rowMeans(log(perplexity_result_dfs))
log(perplexity_result_dfs)
combined_perplexity_results$mean_log <- rowMeans(log(combined_perplexity_results))
View(combined_perplexity_results)
ggplot(combined_perplexity_results, aes(x = seq(55, 80, 5), y = mean_log) ) + geom_dotplot()
qplot(combined_perplexity_results$mean_log)
qplot(seq(55,80,5), combined_perplexity_results$mean_log)
qplot(seq(55,80,5), combined_perplexity_results$mean_log) + geom_line()
qplot(seq(55,80,5), combined_perplexity_results$mean_log, xlab = "Number of topics", title ="Mean of log held-out perplexity from 10-fold cross-validation") + geom_line()
qplot(seq(55,80,5), combined_perplexity_results$mean_log, xlab = "Number of topics") + geom_line() + ggtitle("Mean of log held-out perplexity from 10-fold cross-validation")
qplot(seq(55,80,5), combined_perplexity_results$mean_log, xlab = "Number of topics", ylab = "Mean of log held-out perplexity from 10-fold cross-validation") + geom_line() + ggtitle("Results from held-out perplexity from 10-fold cross-validation")
save.image("perplexity_kfold_combined.RData")
library("ldatuning")
FindTopicsNumber_plot(result)
FindTopicsNumber_plot(result[, c(1,3:5)])
load("/Users/lesliehuang/un-analysis/un_models.RData")
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("~/Desktop/un_models.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
# Examine models with different k
# Sparsity for DFM: min = 0.5%, max = 90%
# TM settings: 5 starts, 4000 iter, 1000 burnin, 500 thin
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
load("un_models.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
# Examine models with different k
# Sparsity for DFM: min = 0.5%, max = 90%
# TM settings: 5 starts, 4000 iter, 1000 burnin, 500 thin
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
# Bring all the results together
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
# Examine models with different k
# Sparsity for DFM: min = 0.5%, max = 90%
# TM settings: 5 starts, 4000 iter, 1000 burnin, 500 thin
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
# Leslie Huang
### Set up the workspace
rm(list=ls())
setwd("/Users/lesliehuang/un-analysis/")
# Bring all the results together
load("un_models.RData")
load("un_ldatuning_results.RData")
load("perplexity_kfold_combined.RData")
set.seed(1234)
libraries <- c("foreign", "utils", "dplyr", "plyr", "devtools", "quanteda", "ggplot2", "topicmodels", "lda", "ldatuning", "LDAvis", "stringi")
lapply(libraries, require, character.only=TRUE)
# Examine models with different k
# Sparsity for DFM: min = 0.5%, max = 90%
# TM settings: 5 starts, 4000 iter, 1000 burnin, 500 thin
generate_wordlist <- function(model, num_words) {
terms <- terms(model, num_words) # matrix, rows = words 1:num_words, cols = topics
t_terms <- t(terms)
t_terms <- as.data.frame(t_terms)
return(t_terms)
}
terms_m50 <- generate_wordlist(model_50, 20)
write.csv(terms_m50, file = "terms_m50.csv")
terms_m65 <- generate_wordlist(model_65, 20)
write.csv(terms_m65, file = "terms_m65.csv")
terms_m75 <- generate_wordlist(model_75, 20)
write.csv(terms_m75, file = "terms_m75.csv")
terms_m80 <- generate_wordlist(model_80, 20)
write.csv(terms_m75, file = "terms_m80.csv")
save.image("full_tm_workspace.RData")
FindTopicsNumber_plot(results[, c(1, 3:5)]) # exclude Griffiths because it's NA
